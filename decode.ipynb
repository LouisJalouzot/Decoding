{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from src.main import main\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"li2022_EN_SS_trimmed_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"datasets\": datasets,\n",
    "    \"model\": \"bert-base-uncased\",\n",
    "    \"decoder\": \"brain_decoder\",\n",
    "    \"loss\": \"mixco\",\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \"context_length\": 6,\n",
    "    \"lag\": 3,\n",
    "    \"smooth\": 6,\n",
    "    \"stack\": 0,\n",
    "    \"dropout\": 0.7,\n",
    "    \"patience\": 20,\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": 1,\n",
    "    \"temperature\": 0.05\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max number of tokens in a chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_config = config.copy()\n",
    "clone_config[\"context_length\"] = 0\n",
    "df_train, df_valid, df_test = main(return_data=True, caching=False, **clone_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = []\n",
    "for df in [df_train, df_valid, df_test]:\n",
    "    for _, row in df.drop_duplicates([\"dataset\", \"run\"]).iterrows():\n",
    "        for chunk in row.text:\n",
    "            num_tokens.append([row.dataset, row.run, len(gpt2.tokenizer.encode(chunk))])\n",
    "num_tokens = pd.DataFrame(num_tokens, columns=[\"dataset\", \"run\", \"num_tokens\"])\n",
    "num_tokens = num_tokens.sort_values(\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.histogram(num_tokens, x=\"num_tokens\", facet_col=\"run\", marginal=\"box\", nbins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid, df_test = main(return_data=True, caching=False, **config)\n",
    "_, decoder = main(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, row = next(iter(df_train.iterrows()))\n",
    "with torch.no_grad():\n",
    "    predicted_latent = decoder(decoder.projector[row.dataset + \"/\" + row.subject](row.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time\"\n",
    "num_sentences = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2(\n",
    "    prompt,\n",
    "    max_new_tokens=12,\n",
    "    num_return_sequences=num_sentences,\n",
    "    pad_token_id=50256,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
