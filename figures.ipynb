{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import wandb, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Helvetica\"\n",
    "plt.rcParams[\"xtick.major.pad\"] = 20\n",
    "plt.rcParams[\"ytick.major.pad\"] = 20\n",
    "plt.rcParams[\"axes.labelpad\"] = 20\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelsize\"] = 20\n",
    "plt.rcParams[\"axes.titlepad\"] = 40\n",
    "plt.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.titlesize\"] = 60\n",
    "plt.rcParams[\"legend.borderpad\"] = 1\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "entity_name = \"louis-jalouzot\"\n",
    "project_name = \"fMRI-Decoding-wrap-up\"\n",
    "api = wandb.Api(\n",
    "    timeout=100, overrides={\"project\": project_name, \"entity\": entity_name}\n",
    ")\n",
    "global_run = wandb.init()\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_artifact(name, split, fold):\n",
    "    artifact = f\"louis-jalouzot/fMRI-Decoding-wrap-up/run-{name}-\"\n",
    "    if fold is not None:\n",
    "        artifact += f\"fold_{fold}\"\n",
    "    artifact += f\"{split}metrics:latest\"\n",
    "    artifact = global_run.use_artifact(artifact, type=\"run_table\")\n",
    "    artifact_dir = artifact.download()\n",
    "    if fold is not None:\n",
    "        artifact_dir += f\"/fold_{fold}\"\n",
    "    artifact_dir += f\"/{split}/metrics.table.json\"\n",
    "    with open(artifact_dir) as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def load_split_folds(name, splits=\"test\", n_folds=15):\n",
    "    df = []\n",
    "    if isinstance(splits, str):\n",
    "        splits = [splits]\n",
    "    if n_folds is not None:\n",
    "        total = n_folds * len(splits)\n",
    "    else:\n",
    "        total = len(splits)\n",
    "\n",
    "    with tqdm(total=total) as pbar:\n",
    "        for split in splits:\n",
    "            if n_folds is not None:\n",
    "                for fold in range(1, n_folds + 1):\n",
    "                    metrics = fetch_artifact(name, split, fold)\n",
    "                    df.append(\n",
    "                        pd.DataFrame(\n",
    "                            metrics[\"data\"], columns=metrics[\"columns\"]\n",
    "                        )\n",
    "                    )\n",
    "                    pbar.update(1)\n",
    "            else:\n",
    "                metrics = fetch_artifact(name, split, None)\n",
    "                df.append(\n",
    "                    pd.DataFrame(metrics[\"data\"], columns=metrics[\"columns\"])\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "    return pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_baseline():\n",
    "    baseline_path = Path(\"figs/baseline.csv.gz\")\n",
    "    if baseline_path.exists():\n",
    "        return pd.read_csv(\"figs/baseline.csv.gz\")\n",
    "    else:\n",
    "        baseline = load_split_folds(\n",
    "            name=\"33582f283c354ab9f545ab5c4cd8866fc46b8fc6\",\n",
    "            splits=[\"train\", \"valid\", \"test\"],\n",
    "            n_folds=None,\n",
    "        )  # random baseline\n",
    "        baseline.to_csv(baseline_path, index=False)\n",
    "        return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(\"figs/setup_df.csv.gz\")\n",
    "if df_path.exists():\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    df = []\n",
    "    runs = api.runs(filters={\"tags\": {\"$in\": [\"setup_v3\"]}})\n",
    "    for run in tqdm(runs):\n",
    "        if run._state == \"finished\":\n",
    "            run_data = run.config | run.summary._json_dict\n",
    "            df.append(pd.json_normalize(run_data))\n",
    "    df = pd.concat(df)\n",
    "    df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = get_baseline()\n",
    "baseline = (\n",
    "    baseline.drop_duplicates([\"run\", \"tr\"])\n",
    "    .groupby(\"run\")\n",
    "    .top_10_accuracy.mean()\n",
    "    .reset_index(name=\"Top 10 Accuracy\")\n",
    ")\n",
    "baseline[\"Setup\"] = \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"model\"] = df[\"latents_cfg.model\"].replace(\n",
    "    {\n",
    "        \"bert-base-uncased\": \"BERT\",\n",
    "        \"McGill-NLP/LLM2Vec-Meta-Llama-31-8B-Instruct-mntp-unsup-simcse\": \"LLM2Vec\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    col\n",
    "    for col in df\n",
    "    if \"top_10_accuracy\" in col\n",
    "    and \"test\" in col\n",
    "    and \"fold\" in col\n",
    "    and \"fmriprep\" in col\n",
    "]\n",
    "id_vars_desc = {\n",
    "    \"latents_cfg.context_length\": \"+ Context Length\",\n",
    "    \"alignment_cfg.lag\": \"+ Lag\",\n",
    "    \"alignment_cfg.smooth\": \"+ Smooth\",\n",
    "    \"model\": \"BERT $\\\\rightarrow$ LLM2Vec\",\n",
    "    \"wrapper_cfg.loss\": \"MSE Loss $\\\\rightarrow$ Contrastive Loss\",\n",
    "    \"decoder_cfg.class\": \"Simple MLP $\\\\rightarrow$ BrainDecoder\",\n",
    "}\n",
    "id_vars = id_vars_desc.keys()\n",
    "tmp = df.melt(\n",
    "    id_vars=id_vars,\n",
    "    value_vars=cols,\n",
    "    value_name=\"Top 10 Accuracy\",\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {col: tmp[col].unique() for col in id_vars}\n",
    "cols[\"model\"] = [\"BERT\", \"LLM2Vec\"]\n",
    "setup = {col: l[0] for col, l in cols.items()}\n",
    "setup[\"Setup\"] = \"Base\"\n",
    "setups = [setup.copy()]\n",
    "for col, l in cols.items():\n",
    "    setup[col] = l[1]\n",
    "    setup[\"Setup\"] = id_vars_desc[col]\n",
    "    setups.append(setup.copy())\n",
    "setups = pd.DataFrame(setups).merge(tmp)\n",
    "setups = pd.concat([baseline, setups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(\n",
    "    data=setups,\n",
    "    y=\"Setup\",\n",
    "    x=\"Top 10 Accuracy\",\n",
    "    hue=\"Setup\",\n",
    "    legend=None,\n",
    "    palette=\"Blues\",\n",
    ")\n",
    "ax.set_xlim(-0.005, ax.get_xlim()[1])\n",
    "ax.set_ylabel(\"\")\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(4))\n",
    "ax.xaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(lambda y, _: f\"{int(100 * y)}%\")\n",
    ")\n",
    "# plt.title(\"Setup comparison\")\n",
    "sns.despine(offset=20, trim=True)\n",
    "plt.savefig(\"paper/figs/setup.pdf\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(\"figs/increase_data_df.csv.gz\")\n",
    "if df_path.exists():\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    df = []\n",
    "    df_sizes = []\n",
    "    runs = api.runs(filters={\"tags\": {\"$in\": [\"increase_data_v2\"]}})\n",
    "    for run in tqdm(runs):\n",
    "        if run._state == \"finished\":\n",
    "            run_data = run.config | run.summary._json_dict\n",
    "            df.append(pd.json_normalize(run_data))\n",
    "    df = pd.concat(df)\n",
    "    df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = [\n",
    "    col\n",
    "    for col in df\n",
    "    if \"fold\" in col\n",
    "    and \"test\" in col\n",
    "    and \"top_10_accuracy\" in col\n",
    "    and \"lebel2023\" in col\n",
    "]\n",
    "tmp = df.melt(\n",
    "    id_vars=[\"train/n_trs\", \"train/size\"],\n",
    "    value_vars=metric_cols,\n",
    "    value_name=\"Top 10 Accuracy\",\n",
    ")\n",
    "tmp[\"Subject\"] = (\n",
    "    tmp.variable.str.split(\"/\")\n",
    "    .apply(lambda x: x[-2])\n",
    "    .str.replace(\"lebel2023_fmriprep_UTS0\", \"\")\n",
    ")\n",
    "tmp[\"Number of training samples\"] = (\n",
    "    tmp[[\"train/n_trs\", \"train/size\"]].max(axis=1).fillna(0)\n",
    ")\n",
    "tmp = tmp.dropna(subset=[\"Top 10 Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_size = tmp[\"Number of training samples\"].max()\n",
    "print(max_train_size * 2 // 60 / 60)\n",
    "print(\n",
    "    tmp[tmp[\"Number of training samples\"] == max_train_size]\n",
    "    .groupby(\"Subject\")[\"Top 10 Accuracy\"]\n",
    "    .mean()\n",
    "    .mean()\n",
    ")\n",
    "tmp[tmp[\"Number of training samples\"] == max_train_size].groupby(\"Subject\")[\n",
    "    \"Top 10 Accuracy\"\n",
    "].mean().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ = tmp[tmp.Subject.astype(int) > 3]\n",
    "tmp_ = tmp_.merge(tmp_.groupby(\"Subject\")[\"Number of training samples\"].max())\n",
    "print((tmp_[\"Number of training samples\"] * 2 // 60 / 60).max())\n",
    "tmp_ = tmp_.groupby(\"Subject\")[\"Top 10 Accuracy\"].mean()\n",
    "print(tmp_.mean())\n",
    "print(tmp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.lineplot(\n",
    "    tmp,\n",
    "    x=\"Number of training samples\",\n",
    "    y=\"Top 10 Accuracy\",\n",
    "    hue=\"Subject\",\n",
    ")\n",
    "# plt.xscale(\"log\")\n",
    "plt.xscale(\"symlog\")\n",
    "plt.xlim(-0.5, 1e4)\n",
    "# plt.yscale(\"log\")\n",
    "ax.yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(lambda y, _: f\"{int(100 * y)}%\")\n",
    ")\n",
    "# ax.xaxis.set_major_formatter(\n",
    "#     ticker.FuncFormatter(\n",
    "#         lambda x, _: f\"$10^{int(np.log10(x))}$\" if x != 100 else 0\n",
    "#     )\n",
    "# )\n",
    "ticklabels = ax.get_xticklabels()\n",
    "for label in ticklabels:\n",
    "    n_mins = (label.get_position()[0] * 2) // 60\n",
    "    n_mins = n_mins // 10 * 10\n",
    "    if n_mins > 60:\n",
    "        n_mins = n_mins // 60\n",
    "        label.set_text(label.get_text() + f\"\\n$\\sim$ {n_mins:.0f} hours\")\n",
    "    elif n_mins > 0:\n",
    "        label.set_text(label.get_text() + f\"\\n$\\sim$ {n_mins:.0f} min\")\n",
    "ax.set_xticklabels(ticklabels)\n",
    "plt.legend(\n",
    "    title=\"Subject\",\n",
    "    loc=\"best\",\n",
    "    ncol=4,\n",
    "    handlelength=1,\n",
    "    labelspacing=0.2,\n",
    "    columnspacing=0.5,\n",
    ")\n",
    "sns.despine()\n",
    "plt.axhline(y=0.005, color=\"gray\", linestyle=\"--\")\n",
    "plt.text(\n",
    "    x=0.99,\n",
    "    y=0.006,\n",
    "    s=\"Chance\",\n",
    "    color=\"gray\",\n",
    "    ha=\"right\",\n",
    "    va=\"bottom\",\n",
    "    transform=ax.get_yaxis_transform(),\n",
    ")\n",
    "plt.savefig(\"paper/figs/increase_data.pdf\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(\"figs/increase_subjects_df.csv.gz\")\n",
    "if df_path.exists():\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    df = []\n",
    "    runs = api.runs(\n",
    "        filters={\"tags\": {\"$in\": [\"increase_subjects_balanced_v2\"]}}\n",
    "    )\n",
    "    for run in tqdm(runs):\n",
    "        if run._state == \"finished\":\n",
    "            run_data = run.config | run.summary._json_dict\n",
    "            df.append(pd.json_normalize(run_data))\n",
    "    df = pd.concat(df)\n",
    "    df[\"n_subjects\"] = df[\"subjects.lebel2023_fmriprep_balanced\"].apply(len)\n",
    "    df[\"subjects.lebel2023_fmriprep_balanced\"] = df[\n",
    "        \"subjects.lebel2023_fmriprep_balanced\"\n",
    "    ].astype(str)\n",
    "    df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    col\n",
    "    for col in df\n",
    "    if \"top_10_accuracy\" in col\n",
    "    and \"test\" in col\n",
    "    and \"fold\" in col\n",
    "    and \"fmriprep\" in col\n",
    "]\n",
    "tmp = df.melt(\n",
    "    id_vars=[\n",
    "        \"n_subjects\",\n",
    "        \"wrapper_cfg.hidden_dim\",\n",
    "        \"subjects.lebel2023_fmriprep_balanced\",\n",
    "    ],\n",
    "    value_vars=cols,\n",
    "    value_name=\"Top 10 Accuracy\",\n",
    "    var_name=\"subject\",\n",
    ")\n",
    "tmp[\"fold\"] = (\n",
    "    tmp.subject.str.split(\"/\")\n",
    "    .apply(lambda x: x[0])\n",
    "    .str.split(\"_\")\n",
    "    .apply(lambda x: x[-1])\n",
    ")\n",
    "tmp[\"subject\"] = (\n",
    "    tmp.subject.str.split(\"/\")\n",
    "    .apply(lambda x: x[-2])\n",
    "    .str.split(\"_\")\n",
    "    .apply(lambda x: x[-1])\n",
    "    .str.replace(\"UTS0\", \"\")\n",
    ")\n",
    "tmp = tmp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_perfs = tmp[tmp.n_subjects == 1][\n",
    "    [\"wrapper_cfg.hidden_dim\", \"subject\", \"fold\", \"Top 10 Accuracy\"]\n",
    "]\n",
    "tmp = tmp.merge(\n",
    "    single_perfs,\n",
    "    on=[\"wrapper_cfg.hidden_dim\", \"subject\", \"fold\"],\n",
    "    suffixes=(\"\", \" single\"),\n",
    ")\n",
    "tmp[\"Multi - single\\nTop 10 Accuracy\"] = (\n",
    "    tmp[\"Top 10 Accuracy\"] - tmp[\"Top 10 Accuracy single\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_scores = tmp.groupby(\n",
    "    [\n",
    "        \"subject\",\n",
    "        \"wrapper_cfg.hidden_dim\",\n",
    "        \"subjects.lebel2023_fmriprep_balanced\",\n",
    "        \"n_subjects\",\n",
    "    ]\n",
    ")[\"Top 10 Accuracy\"].mean()\n",
    "best_combis = combi_scores.groupby(\n",
    "    [\"subject\", \"n_subjects\", \"wrapper_cfg.hidden_dim\"]\n",
    ").idxmax()\n",
    "best_combis = (\n",
    "    combi_scores[best_combis].reset_index().drop(columns=\"Top 10 Accuracy\")\n",
    ")\n",
    "tmp = tmp.merge(best_combis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=tmp,\n",
    "    x=\"n_subjects\",\n",
    "    y=\"Multi - single\\nTop 10 Accuracy\",\n",
    "    hue=\"subject\",\n",
    "    kind=\"line\",\n",
    "    col=\"wrapper_cfg.hidden_dim\",\n",
    "    height=6,\n",
    "    aspect=1.5,\n",
    "    palette=\"tab10\",\n",
    "    legend=\"full\",\n",
    ")\n",
    "g.axes[0, 0].yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(lambda y, _: f\"{int(100 * y)}%\")\n",
    ")\n",
    "g.set_titles(\"Hidden dim: {col_name}\")\n",
    "g.set_axis_labels(\"Number of subjects\")\n",
    "sns.despine(offset=10, trim=True)\n",
    "g.legend.set(\n",
    "    title=\"Subject\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    loc=\"center right\",\n",
    "    frame_on=True,\n",
    ")\n",
    "plt.legend(\n",
    "    bbox_to_anchor=(1.3, 1), loc=\"upper left\", borderaxespad=0.0, frameon=False\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls=\"--\", color=\"black\", alpha=0.5)\n",
    "plt.savefig(\n",
    "    \"paper/figs/increase_subjects.pdf\", bbox_inches=\"tight\", pad_inches=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(\"figs/overlap_v2_df.csv.gz\")\n",
    "if df_path.exists():\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    df = []\n",
    "    runs = api.runs(filters={\"tags\": {\"$in\": [\"overlap_v2\"]}})\n",
    "    for run in tqdm(runs):\n",
    "        if run._state == \"finished\":\n",
    "            run_data = run.config | run.summary._json_dict\n",
    "            df.append(pd.json_normalize(run_data))\n",
    "    df = pd.concat(df)\n",
    "    df[\"n_subjects\"] = df[\"subjects.lebel2023_fmriprep\"].apply(len)\n",
    "    df[\"subjects.lebel2023_fmriprep\"] = df[\n",
    "        \"subjects.lebel2023_fmriprep\"\n",
    "    ].astype(str)\n",
    "    df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    col\n",
    "    for col in df\n",
    "    if \"top_10_accuracy\" in col\n",
    "    and \"test\" in col\n",
    "    and \"fold\" in col\n",
    "    and \"fmriprep\" in col\n",
    "]\n",
    "tmp = df.melt(\n",
    "    id_vars=[\n",
    "        \"n_subjects\",\n",
    "        \"wrapper_cfg.hidden_dim\",\n",
    "        \"splitting.overlap\",\n",
    "        \"subjects.lebel2023_fmriprep\",\n",
    "    ],\n",
    "    value_vars=cols,\n",
    "    value_name=\"Top 10 Accuracy\",\n",
    "    var_name=\"subject\",\n",
    ")\n",
    "tmp[\"fold\"] = (\n",
    "    tmp.subject.str.split(\"/\")\n",
    "    .apply(lambda x: x[0])\n",
    "    .str.split(\"_\")\n",
    "    .apply(lambda x: x[-1])\n",
    ")\n",
    "tmp[\"subject\"] = (\n",
    "    tmp.subject.str.split(\"/\")\n",
    "    .apply(lambda x: x[-2])\n",
    "    .str.split(\"_\")\n",
    "    .apply(lambda x: x[-1])\n",
    "    .str.replace(\"UTS0\", \"\")\n",
    ")\n",
    "tmp = tmp[(tmp.n_subjects > 1) + (tmp[\"splitting.overlap\"] == 1)]\n",
    "tmp = tmp.dropna()\n",
    "single_subject = tmp[tmp.n_subjects == 1][\n",
    "    [\"wrapper_cfg.hidden_dim\", \"subject\", \"fold\", \"Top 10 Accuracy\"]\n",
    "]\n",
    "tmp = tmp.merge(\n",
    "    single_subject,\n",
    "    on=[\"wrapper_cfg.hidden_dim\", \"subject\", \"fold\"],\n",
    "    suffixes=(\"\", \" single\"),\n",
    ")\n",
    "tmp[\"Top 10 Accuracy\"] = tmp[\"Top 10 Accuracy\"] - tmp[\"Top 10 Accuracy single\"]\n",
    "tmp = tmp[tmp.n_subjects == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.groupby([\"subject\", \"wrapper_cfg.hidden_dim\", \"splitting.overlap\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=tmp,\n",
    "    x=\"splitting.overlap\",\n",
    "    y=\"Top 10 Accuracy\",\n",
    "    kind=\"line\",\n",
    "    col=\"wrapper_cfg.hidden_dim\",\n",
    "    hue=\"subject\",\n",
    "    height=6,\n",
    "    aspect=1.5,\n",
    "    hue_order=sorted(tmp.subject.unique()),\n",
    ")\n",
    "g.axes[0, 0].yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(lambda y, _: f\"{int(round(100 * y,0))}%\")\n",
    ")\n",
    "g.set_axis_labels(\"Stimuli overlap\", \"Multi - single\\nTop 10 Accuracy\")\n",
    "g.set_titles(\"Hidden dim: {col_name}\")\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls=\"--\", color=\"black\", alpha=0.5)\n",
    "g.legend.set(\n",
    "    title=\"Subject\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    loc=\"center right\",\n",
    "    frame_on=True,\n",
    ")\n",
    "plt.legend(\n",
    "    [],\n",
    "    [],\n",
    "    bbox_to_anchor=(1.25, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.0,\n",
    "    frameon=False,\n",
    ")\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.savefig(\"paper/figs/overlap.pdf\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntax/semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = get_baseline()\n",
    "df_path = Path(\"figs/zoom_in_nlp_100.csv.gz\")\n",
    "if df_path.exists():\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    df = load_split_folds(\n",
    "        \"b2af211a703e07acc44416e4bafa8c35fb85e65c\"\n",
    "    )  # zoom_in_nlp_100\n",
    "    df.to_csv(df_path, index=False)\n",
    "baseline = baseline[[\"glove_bow_pos_restricted_cosine\", \"pos_ratio\"]].mean()\n",
    "df[[\"glove_bow_pos_restricted_cosine\", \"pos_ratio\"]] = (\n",
    "    df[[\"glove_bow_pos_restricted_cosine\", \"pos_ratio\"]] - baseline\n",
    ") / baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.query(\"top < 50\").melt(\n",
    "    id_vars=[\"top\"],\n",
    "    value_vars=[\"glove_bow_pos_restricted_cosine\", \"pos_ratio\"],\n",
    "    var_name=\"metric\",\n",
    "    value_name=\"Normalized similarity\",\n",
    ")\n",
    "tmp[\"metric\"] = tmp.metric.replace(\n",
    "    {\"glove_bow_pos_restricted_cosine\": \"Semantic\", \"pos_ratio\": \"Syntactic\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=tmp,\n",
    "    x=\"top\",\n",
    "    y=\"Normalized similarity\",\n",
    "    hue=\"metric\",\n",
    "    col=\"metric\",\n",
    "    kind=\"bar\",\n",
    "    palette=\"tab10\",\n",
    "    height=7,\n",
    "    aspect=1.5,\n",
    "    dodge=0,\n",
    "    edgecolor=\"none\",\n",
    "    width=1,\n",
    "    err_kws={\"linewidth\": 1.5},\n",
    "    legend=None,\n",
    "    col_order=[\"Syntactic\", \"Semantic\"],\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    if ax.get_ylabel():\n",
    "        ax.set_ylabel(\"Normalized similarity\", labelpad=10)\n",
    "    ax.set_xlabel(\"Candidate rank\", labelpad=10)\n",
    "    ax.xaxis.set_major_locator(ticker.LinearLocator(5))\n",
    "sns.despine(offset=20, trim=True)\n",
    "g.set_titles(template=\"{col_name}\")\n",
    "g.axes[0, 0].yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(lambda y, _: f\"{int(100 * y)}%\")\n",
    ")\n",
    "plt.savefig(\n",
    "    \"paper/figs/nlp_similarities.pdf\", bbox_inches=\"tight\", pad_inches=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"figs/zoom_in_nlp.csv\")\n",
    "baseline = get_baseline()\n",
    "nlp_distances = [\n",
    "    \"glove_bow_cosine\",\n",
    "    \"glove_bow_pos_restricted_cosine\",\n",
    "    \"pos_ratio\",\n",
    "    \"ratio\",\n",
    "]\n",
    "baseline = baseline[nlp_distances].agg([\"mean\", \"std\"])\n",
    "baseline = baseline.T.reset_index(names=\"distance\")\n",
    "df = df.merge(baseline, on=\"distance\", suffixes=(\"\", \"_baseline\"))\n",
    "df[\"mean\"] = (df[\"mean\"] - df[\"mean_baseline\"]) / df[\"mean_baseline\"]\n",
    "# df[\"std\"] = df[\"std\"] / df[\"mean_baseline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter, FuncFormatter\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.lineplot(data=df, x=\"top\", y=\"mean\", hue=\"distance\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.5), loc=\"center left\")\n",
    "# for distance in df[\"distance\"].unique():\n",
    "#     plt.fill_between(\n",
    "#         df[df[\"distance\"] == distance][\"top\"],\n",
    "#         df[df[\"distance\"] == distance][\"mean\"]\n",
    "#         - df[df[\"distance\"] == distance][\"std\"],\n",
    "#         df[df[\"distance\"] == distance][\"mean\"]\n",
    "#         + df[df[\"distance\"] == distance][\"std\"],\n",
    "#         alpha=0.2,\n",
    "#     )\n",
    "plt.xlabel(\"Candidate rank\")\n",
    "plt.ylabel(\"Normalized similarity\")\n",
    "plt.xscale(\"log\")\n",
    "# plt.title(\"(similarity - baseline mean) / baseline std\")\n",
    "plt.title(\"(similarity - baseline mean) / baseline mean\")\n",
    "ax.axhline(0, ls=\"--\", color=\"black\", alpha=0.5)\n",
    "# ax.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:.1f} $\\sigma$\"))\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{int(100 * x)}%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df,\n",
    "    x=\"top\",\n",
    "    y=\"mean\",\n",
    "    color=\"distance\",\n",
    "    error_y=df[\"std\"],\n",
    "    log_y=True,\n",
    "    # log_x=True,\n",
    "    height=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(\"top\")[nlp_distances].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_csv(\"figs/zoom_in_nlp_all_agg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df.xs(\"mean\", axis=1, level=1).copy()\n",
    "df_mean[\"top\"] = df.top\n",
    "df_std = df.xs(\"std\", axis=1, level=1).copy()\n",
    "df_std[\"top\"] = df.top\n",
    "df = df_mean.merge(df_std, on=\"top\", suffixes=(\"\", \"_std\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"figs/zoom_in_nlp_all_agg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_runs = df.groupby(\"run\").top_10_accuracy.mean().sort_values()\n",
    "best_runs = sorted_runs.iloc[-20:].index\n",
    "worst_runs = sorted_runs.iloc[:20].index\n",
    "tmp = (\n",
    "    df[(df.run.isin(best_runs)) + (df.run.isin(worst_runs))]\n",
    "    .query(\"top < 80\")\n",
    "    .copy()\n",
    ")\n",
    "tmp[\"run_type\"] = \"20 Worst stories\"\n",
    "tmp.loc[tmp.run.isin(best_runs), \"run_type\"] = \"20 Best stories\"\n",
    "tmp = tmp.melt(\n",
    "    id_vars=[\"top\", \"run_type\"],\n",
    "    value_vars=[\"glove_bow_pos_restricted_cosine\", \"pos_ratio\"],\n",
    "    var_name=\"metric\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    tmp,\n",
    "    palette=\"tab10\",\n",
    "    row=\"metric\",\n",
    "    col=\"run_type\",\n",
    "    sharey=False,\n",
    "    height=5,\n",
    "    aspect=1.5,\n",
    ")\n",
    "g.map_dataframe(\n",
    "    sns.barplot,\n",
    "    x=\"top\",\n",
    "    y=\"value\",\n",
    "    hue=\"run_type\",\n",
    "    palette=\"tab10\",\n",
    "    hue_order=[\"20 Best stories\", \"20 Worst stories\"],\n",
    "    err_kws={\"linewidth\": 1.5},\n",
    "    dodge=0,\n",
    "    edgecolor=\"none\",\n",
    "    width=1,\n",
    ")\n",
    "g.set_titles(template=\"{col_name}/{row_name}\")\n",
    "for i, ax in enumerate(g.axes.flat):\n",
    "    run_type, metric = ax.get_title().split(\"/\")\n",
    "    if ax.get_ylabel():\n",
    "        if metric == \"glove_bow_pos_restricted_cosine\":\n",
    "            ax.set_ylabel(\"Semantic\", labelpad=20)\n",
    "        elif metric == \"pos_ratio\":\n",
    "            ax.set_ylabel(\"Syntactic\", labelpad=20)\n",
    "    if i // 2 == 0:\n",
    "        ax.set_title(run_type)\n",
    "    else:\n",
    "        ax.set_title(\"\")\n",
    "    if ax.get_xlabel():\n",
    "        ax.set_xlabel(\"Candidate rank\", labelpad=20)\n",
    "    ax.xaxis.set_major_locator(ticker.LinearLocator(9))\n",
    "sns.despine(offset=20, trim=True)\n",
    "plt.suptitle(\"Normalized NLP similarities (ratio above baseline)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"paper/figs/nlp_similarities.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
